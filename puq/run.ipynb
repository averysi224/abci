{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### comment after the first run\n",
    "!git clone https://github.com/averysi224/abci.git\n",
    "\n",
    "%cd abci\n",
    "!pip install -e .\n",
    "!pip install archetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da8a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "%cd puq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4455cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "from torchvision.transforms import transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from puq.core import DAPUQUncertaintyRegion\n",
    "from puq.arch_sample import hvf_json\n",
    "from puq.data.data import (\n",
    "    DiffusionSamplesDataset,\n",
    "    GroundTruthsDataset,\n",
    "    DiffusionSamplesDataLoader,\n",
    "    GroundTruthsDataLoader,\n",
    ")\n",
    "from puq.plotting.visual import plot_archetype_matrices\n",
    "from puq.utils import misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a7077bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    method=\"da_puq\",                           \n",
    "    data=\"/data5/wenwens/UW_subgroups/moderate\",\n",
    "    test_ratio=0.2,                             \n",
    "    seed=42,\n",
    "    gpu=0,                                      \n",
    "    batch=4,\n",
    "    num_workers=0,\n",
    "    no_cache=False,\n",
    "\n",
    "    alpha=0.25,                                 \n",
    "    beta=0.14,                                  \n",
    "    q=0.9,                                      \n",
    "    delta=0.1,                                  \n",
    "\n",
    "    num_reconstruction_lambdas=17,\n",
    "    num_coverage_lambdas=100,\n",
    "    num_pcs_lambdas=20,\n",
    "    max_coverage_lambda=800.0,\n",
    "\n",
    "    archetypes=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecb60bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if args.gpu is not None and torch.cuda.is_available():\n",
    "    device = torch.device(f\"cuda:{args.gpu}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93e3afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vf(sample):\n",
    "    \"\"\"\n",
    "    Convert alg outputs to plotting format (9x9 VF grid).\n",
    "    sample: 81-dim tensor (flattened 9x9), defined on hvf_json coordinates.\n",
    "    \"\"\"\n",
    "    coordinates = [(entry[\"x\"], entry[\"y\"]) for entry in hvf_json]\n",
    "    vf = [1.0 for _ in range(81)]\n",
    "    vf[34] = 0.0\n",
    "    vf[43] = 0.0\n",
    "    for j in range(len(coordinates)):\n",
    "        idx = coordinates[j][0] * 9 + coordinates[j][1]\n",
    "        vf[idx] = sample[idx].item()\n",
    "    return torch.tensor(vf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40327360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "namespace(alpha=0.25, archetypes=True, batch=4, beta=0.14, data='/data5/wenwens/UW_subgroups/moderate', delta=0.1, gpu=0, max_coverage_lambda=800.0, method='da_puq', no_cache=False, num_coverage_lambdas=100, num_pcs_lambdas=20, num_reconstruction_lambdas=17, num_workers=0, q=0.9, seed=42, test_ratio=0.2)\n",
      "namespace(alpha=0.25, archetypes=True, batch=4, beta=0.14, data='/data5/wenwens/UW_subgroups/moderate', delta=0.1, gpu=0, max_coverage_lambda=800.0, method='da_puq', no_cache=False, num_coverage_lambdas=100, num_pcs_lambdas=20, num_reconstruction_lambdas=17, num_workers=0, q=0.9, seed=42, test_ratio=0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying approximation phase...\n",
      "Applying approximation phase...\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.46it/s]\n",
      "Applying calibration phase...\n",
      "Applying calibration phase...\n",
      "Successfully calibrated: lambda1=0.125, lambda2=243.1212158203125\n",
      "Successfully calibrated: lambda1=0.125, lambda2=243.1212158203125\n",
      "Applying evaluation...\n",
      "Applying evaluation...\n",
      "100%|██████████| 33/33 [00:09<00:00,  3.33it/s]\n",
      "{'coverage_risk': 0.15552585165609012, 'reconstruction_risk': 0.08954099825385844, 'interval_size': 0.02144144650435809, 'dimension': 1.5454545454545454, 'max_dimension': 200.0, 'uncertainty_volume': 4.330704385169921e-10}\n",
      "{'coverage_risk': 0.15552585165609012, 'reconstruction_risk': 0.08954099825385844, 'interval_size': 0.02144144650435809, 'dimension': 1.5454545454545454, 'max_dimension': 200.0, 'uncertainty_volume': 4.330704385169921e-10}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results: {'coverage_risk': 0.15552585165609012, 'reconstruction_risk': 0.08954099825385844, 'interval_size': 0.02144144650435809, 'dimension': 1.5454545454545454, 'max_dimension': 200.0, 'uncertainty_volume': 4.330704385169921e-10}\n"
     ]
    }
   ],
   "source": [
    "misc.setup_logging(os.path.join(os.getcwd(), \"log.txt\"))\n",
    "logging.info(args)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if not os.path.exists(\"results\"):\n",
    "    os.makedirs(\"results\")\n",
    "\n",
    "puq = DAPUQUncertaintyRegion(args)\n",
    "\n",
    "cal_samples_dataset = DiffusionSamplesDataset(\n",
    "    opt=args,\n",
    "    calibration=True,\n",
    "    transform=T.Compose([\n",
    "        T.Grayscale(num_output_channels=1),\n",
    "        T.ToTensor(),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "cal_ground_truths_dataset = GroundTruthsDataset(\n",
    "    opt=args,\n",
    "    samples_dataset=cal_samples_dataset,\n",
    "    transform=T.Compose([\n",
    "        T.Grayscale(num_output_channels=1),\n",
    "        T.ToTensor(),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "puq.calibration(cal_samples_dataset, cal_ground_truths_dataset)\n",
    "\n",
    "test_samples_dataset = DiffusionSamplesDataset(\n",
    "    opt=args,\n",
    "    calibration=False,\n",
    "    transform=T.Compose([\n",
    "        T.Grayscale(num_output_channels=1),\n",
    "        T.ToTensor(),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "test_ground_truths_dataset = GroundTruthsDataset(\n",
    "    opt=args,\n",
    "    samples_dataset=test_samples_dataset,\n",
    "    transform=T.Compose([\n",
    "        T.Grayscale(num_output_channels=1),\n",
    "        T.ToTensor(),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "results = puq.eval(test_samples_dataset, test_ground_truths_dataset)\n",
    "print(\"Eval results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ea6de90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num test batches: 32\n",
      "interval size: 0.09185771644115448\n"
     ]
    }
   ],
   "source": [
    "# visualization\n",
    "\n",
    "dl = DiffusionSamplesDataLoader(\n",
    "    test_samples_dataset,\n",
    "    batch_size=args.batch,\n",
    "    num_workers=args.num_workers,\n",
    ")\n",
    "\n",
    "gl = GroundTruthsDataLoader(\n",
    "    test_ground_truths_dataset,\n",
    "    batch_size=args.batch,\n",
    "    num_workers=args.num_workers,\n",
    ")\n",
    "\n",
    "dl_iter = iter(dl)\n",
    "gl_iter = iter(gl)\n",
    "\n",
    "all_diff = 0.0\n",
    "cnt = 0\n",
    "\n",
    "# 读取 archetype 矩阵\n",
    "archetypes = pd.read_csv(\"./plotting/at17_matrix.csv\").values\n",
    "\n",
    "num_batches = len(test_ground_truths_dataset) // args.batch\n",
    "print(\"Num test batches:\", num_batches)\n",
    "\n",
    "for i_batch in range(num_batches):\n",
    "    image_shape = [1, 9, 9]\n",
    "\n",
    "    batch_samples = next(dl_iter).flatten(2)           # [B, C*H*W]\n",
    "    batch_gt = next(gl_iter).flatten(2).squeeze()      # [B, C*H*W] or [B, H*W]\n",
    "    batch_gt = [plot_vf(i.cpu()) for i in batch_gt]\n",
    "\n",
    "    batch_mu, batch_pcs, batch_svs, batch_lower, batch_upper, batch_indices = puq.inference(batch_samples)\n",
    "\n",
    "    batch_mu = [plot_vf(i.cpu()) for i in batch_mu]\n",
    "    batch_pcs = [i.cpu() for i in batch_pcs]\n",
    "    batch_svs = [i.cpu() for i in batch_svs]\n",
    "    batch_lower = [i.cpu() for i in batch_lower]\n",
    "    batch_upper = [i.cpu() for i in batch_upper]\n",
    "    batch_indices = [i.cpu() for i in batch_indices]\n",
    "\n",
    "    fig, axs = plt.subplots(args.batch, 8, figsize=(20, 10))\n",
    "\n",
    "    for i in range(args.batch):\n",
    "        axs[i, 0].imshow(\n",
    "            batch_mu[i].view(image_shape).transpose(0, 1).transpose(1, 2),\n",
    "            cmap=\"gray\",\n",
    "        )\n",
    "        axs[i, 0].axis(\"off\")\n",
    "\n",
    "        lower_image = (batch_mu[i] + batch_pcs[i] @ batch_lower[i]).clamp_(0, 1)\n",
    "        axs[i, 1].imshow(\n",
    "            lower_image.view(image_shape).transpose(0, 1).transpose(1, 2),\n",
    "            cmap=\"gray\",\n",
    "        )\n",
    "        axs[i, 1].axis(\"off\")\n",
    "\n",
    "        upper_image = (batch_mu[i] + batch_pcs[i] @ batch_upper[i]).clamp_(0, 1)\n",
    "        axs[i, 2].imshow(\n",
    "            upper_image.view(image_shape).transpose(0, 1).transpose(1, 2),\n",
    "            cmap=\"gray\",\n",
    "        )\n",
    "        axs[i, 2].axis(\"off\")\n",
    "\n",
    "        # ground truth\n",
    "        axs[i, 3].imshow(\n",
    "            batch_gt[i].view(image_shape).transpose(0, 1).transpose(1, 2),\n",
    "            cmap=\"gray\",\n",
    "        )\n",
    "        axs[i, 3].axis(\"off\")\n",
    "\n",
    "        # interval\n",
    "        diff = torch.abs(upper_image - lower_image).sum() / 52.0\n",
    "        all_diff += diff\n",
    "        cnt += 1\n",
    "\n",
    "        # archetype 0 does not count as visual loss\n",
    "        selected_pcs = batch_indices[i]\n",
    "        selected_pcs = selected_pcs[selected_pcs != 0]\n",
    "\n",
    "        # top-4 high-contributing archetypes\n",
    "        for axis_i in range(4):\n",
    "            if batch_pcs[i].shape[1] > axis_i and axis_i < len(selected_pcs):\n",
    "                plot_archetype_matrices(\n",
    "                    axs[i, axis_i + 4],\n",
    "                    selected_pcs[axis_i],\n",
    "                    archetypes,\n",
    "                )\n",
    "            axs[i, axis_i + 4].axis(\"off\")\n",
    "\n",
    "    cols = [\n",
    "        \"average\\nprediction\",\n",
    "        \"lower\\nbound\",\n",
    "        \"upper\\nbound\",\n",
    "        \"ground\\ntruth\",\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"main uncertainty components\\n\",\n",
    "        \"\",\n",
    "    ]\n",
    "    for ax, col in zip(axs[0], cols):\n",
    "        ax.set_title(col, fontsize=20, pad=20)\n",
    "\n",
    "    dis = [0.93, 0.8, 0.6, 0.4, 0.2]\n",
    "    texts = [\"patient\", \"   1   \", \"   2   \", \"   3   \", \"   4   \"]\n",
    "    for row_idx, text in enumerate(texts):\n",
    "        fig.text(\n",
    "            x=0.05,\n",
    "            y=dis[row_idx],\n",
    "            s=text,\n",
    "            va=\"center\",\n",
    "            ha=\"left\",\n",
    "            fontsize=20,\n",
    "        )\n",
    "\n",
    "    stage = args.data.split(\"/\")[-1]\n",
    "    fig.suptitle(\"\", fontsize=20, y=0.95)\n",
    "    plt.savefig(f\"results/{stage}_{args.alpha}_bounds_{i_batch}.png\")\n",
    "    plt.close()\n",
    "\n",
    "interval_size = (all_diff / cnt).item()\n",
    "print(\"interval size:\", interval_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
